{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15b7a7e67cf44dcb81f15c281df6920b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_651e32ee90ff4c688354dbc06561740f",
              "IPY_MODEL_a84e08403c524ca2950241fed8f4bc56",
              "IPY_MODEL_59e7caaca11c4878b59f422ba6110092"
            ],
            "layout": "IPY_MODEL_be22fbf8545348af9553e7d922b64a88"
          }
        },
        "651e32ee90ff4c688354dbc06561740f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1884f43f9a1401ea97a72e31bb0f22a",
            "placeholder": "​",
            "style": "IPY_MODEL_2f960eec03d141a997cec16524383ce9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a84e08403c524ca2950241fed8f4bc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4212706bd522490cbf9f8fbbe90db9a9",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61b073fe673f4b63ae4eff18453ae38b",
            "value": 33
          }
        },
        "59e7caaca11c4878b59f422ba6110092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cf05eda4d8b4f4fa962569ba1d32cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_dd37f54f56384eb88bc2703f2b1d70f5",
            "value": " 33/33 [01:15&lt;00:00,  2.55s/it]"
          }
        },
        "be22fbf8545348af9553e7d922b64a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1884f43f9a1401ea97a72e31bb0f22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f960eec03d141a997cec16524383ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4212706bd522490cbf9f8fbbe90db9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61b073fe673f4b63ae4eff18453ae38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cf05eda4d8b4f4fa962569ba1d32cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd37f54f56384eb88bc2703f2b1d70f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunyeul/ToyProjectLab/blob/feature%2Fjapanese-alpaca-fine-tuning/Japanese_Alpaca_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/assets/logo.png)"
      ],
      "metadata": {
        "id": "TB7CxP8lu8XH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alpacaの概要\n",
        "\n",
        "- Alpacaは、MetaのLLaMA 7Bモデルから微調整され、OpenAIのtext-davinci-003に似た性能を示す\n",
        "\n",
        "- Alpacaは小型で再現が容易かつ安価\n",
        "\n",
        "- Alpacaは学術研究専用で、商用利用は禁止されている\n",
        "\n",
        "    - 商用利用禁止の理由は、LLaMAの非営利ライセンス継承、OpenAIの利用規約による競合禁止、十分な安全対策がないため。\n",
        "\n",
        "![トレーニングレシピ](https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_main.jpg)"
      ],
      "metadata": {
        "id": "u_v1SUFLu1Yj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZGIsAB-uuli",
        "outputId": "64dcba72-0b0d-49cf-b0b1-d68dd77acc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  8 07:08:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ダウンロードソースコード\n",
        "\n",
        "\n",
        "- https://github.com/tloen/alpaca-lora.git\n",
        "- peftバグ：https://github.com/tloen/alpaca-lora/issues/293"
      ],
      "metadata": {
        "id": "7En6ZBEdvQZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -qq https://github.com/tloen/alpaca-lora.git\n",
        "%cd alpaca-lora\n",
        "!pip install -r requirements.txt -qq\n",
        "!pip uninstall peft -y -qq\n",
        "!pip install -qq git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s179g_hOvOAx",
        "outputId": "6174391a-4eff-449a-adc2-f9042c6c7921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'alpaca-lora' already exists and is not an empty directory.\n",
            "/content/alpaca-lora\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 原本のデータセット\n",
        "\n",
        "- Fine-tuning用に使われた命令追従型の学習データ\n",
        "    - https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json\n",
        "    - https://huggingface.co/datasets/tatsu-lab/alpaca/viewer/tatsu-lab--alpaca\n",
        "\n",
        "    - instruction: str - モデルが実行すべきタスクを記述。52Kの指示はユニーク\n",
        "\n",
        "    - input: str - タスクのオプションのコンテキストまたは入力。たとえば、指示が「次の記事を要約」の場合、入力は記事。例の約40%には入力がある\n",
        "\n",
        "    - output: str - 「text-davinci-003」によって生成された指示に対する回答\n",
        "\n",
        "```JSON\n",
        "[\n",
        "    ...,\n",
        "    {\n",
        "        \"instruction\": \"Give three tips for staying healthy.\",\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Explain why the following fraction is equivalent to 1/4\",\n",
        "        \"input\": \"4/16\",\n",
        "        \"output\": \"The fraction 4/16 is equivalent to 1/4 because both numerators and denominators are divisible by 4. Dividing both the top and bottom numbers by 4 yields the fraction 1/4.\"\n",
        "    },\n",
        "    ...\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "Ml90DHRVvsLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 和訳データセット\n",
        "\n",
        "- ChatGPT翻訳： https://raw.githubusercontent.com/masa3141/japanese-alpaca-lora/main/data/japanese_alpaca_data.json\n",
        "\n",
        "```JSON\n",
        "[\n",
        "    ...,\n",
        "    {\n",
        "        \"instruction\": \"「健康を維持するための3つのヒントを教えてください。」\",\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"「バランスの良い食事を摂り、果物や野菜をたっぷりと含めるようにしてください。\\n2. 定期的に運動して、体を活発で強く保ちましょう。\\n3. 十分な睡眠をとり、一定の睡眠スケジュールを維持してください。」\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"「以下の分数が1/4と等しい理由を説明してください。」\",\n",
        "        \"input\": \"'4/16'は日付を表しています。\",\n",
        "        \"output\": \"「4/16の分数は、両方の分子と分母が4で割り切れるため、1/4と等しいです。上部と下部の数値を両方とも4で割ると、1/4の分数が得られます。」\"\n",
        "    },\n",
        "    ...\n",
        "]\n",
        "```\n",
        "\n",
        "- https://raw.githubusercontent.com/shi3z/alpaca_ja/main/alpaca_data_ja.json\n",
        "\n",
        "\n",
        "```JSON\n",
        "[\n",
        "    ...,\n",
        "    {\n",
        "        \"instruction\":  \"健康維持のための3つのコツを教えてください。\\n\",\n",
        "        \"input\":\"\\n\",\n",
        "        \"output\":\"1、バランスのとれた食事を摂り、野菜や果物を十分に摂ること。2、定期的に運動をして体の活力を保つこと。3、睡眠時間を十分にとり、規則正しい睡眠をとること。\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\":  \"次の分数が1/4に相当する理由を説明せよ。\\n\",\n",
        "        \"input\":\"4/16個\\n\",\n",
        "        \"output\":\"分数4/16は1/4に相当します。これは、分子と分母の両方が4で割り切れるためです。上の数値と下の数値の両方を4で割ると、分数1/4が得られます。\\n\"\n",
        "    },\n",
        "    ...\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "lTn4my0uv__Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/masa3141/japanese-alpaca-lora/main/data/japanese_alpaca_data.json\n",
        "\n",
        "import json\n",
        "\n",
        "with open('japanese_alpaca_data.json', 'r', encoding='UTF-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "dataset[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuilHhBJvl5O",
        "outputId": "495baa43-6fa1-4d27-83ba-a268ca81da5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'instruction': '「健康を維持するための3つのヒントを教えてください。」',\n",
              "  'input': '',\n",
              "  'output': '「バランスの良い食事を摂り、果物や野菜をたっぷりと含めるようにしてください。\\n2. 定期的に運動して、体を活発で強く保ちましょう。\\n3. 十分な睡眠をとり、一定の睡眠スケジュールを維持してください。」'},\n",
              " {'instruction': '「三原色とは何ですか？」', 'input': '', 'output': '「三原色は赤、青、黄色です。」'},\n",
              " {'instruction': '「原子の構造を説明してください。」',\n",
              "  'input': '',\n",
              "  'output': '「原子は、陽子と中性子を含む核と、核の周りを軌道を描いて移動する電子から構成されています。陽子と中性子は正の電荷を持ち、電子は負の電荷を持っており、全体としては中性の原子になります。各粒子の数が原子番号と原子の種類を決定します。」'},\n",
              " {'instruction': '「どうすれば大気汚染を減らせますか？」',\n",
              "  'input': '',\n",
              "  'output': '「再生可能エネルギー源への移行、公共交通機関の利用促進、化石燃料の燃焼禁止、産業源からの排出削減政策の実施、車両排出基準の実施など、大気汚染を減らすための方法はいくつかあります。さらに、個人は車の利用を減らしたり、木材の燃焼を避けたり、省エネ家電に切り替えたりすることで、大気汚染を減らすことができます。」'},\n",
              " {'instruction': '「あなたが困難な決断をしなければならなかった時について説明してください。」',\n",
              "  'input': '',\n",
              "  'output': '私は建設会社でプロジェクトマネージャーとして働いていた時、困難な決断をしなければならない状況に陥りました。私が担当していたプロジェクトは、クライアントの期待に応えるためにある特定の日までに完成しなければならなかったのですが、予期せぬ遅延が発生し、期限に間に合わなくなってしまいました。そこで、私は困難な決断を下すことになりました。私は期限を延長することを決めましたが、チームのリソースをさらに使い果たし、予算を増やす必要がありました。リスクのある決断でしたが、プロジェクトを期限通りに完了し、クライアントの期待に応えるために、私は最終的にその決断を下すことにしました。結果的に、プロジェクトは成功裏に完了し、私のリーダーシップと意思決定能力の証として認められました。'}]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## カスタムプロンプト\n",
        "\n",
        "- 原本のプロンプト\n",
        "\n",
        "```JSON\n",
        "{\n",
        "    \"description\": \"Template used by Alpaca-LoRA.\",\n",
        "    \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n",
        "    \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n",
        "    \"response_split\": \"### Response:\"    \n",
        "}\n",
        "```\n",
        "\n",
        "- 和駅のカスタムプロンプト\n",
        "\n",
        "```JSON\n",
        "{\n",
        "    \"description\": \"Alpaca-LoRAが使用するテンプレート。\",\n",
        "    \"prompt_input\": \"以下に、タスクを説明する指示と、さらなる文脈を提供する入力がペアになっています。要求に適切に対応する回答を記述してください。\\n\\n### 指示:\\n{instruction}\\n\\n### 入力:\\n{input}\\n\\n### 回答:\\n\",\n",
        "    \"prompt_no_input\": \"以下に、タスクを説明する指示があります。要求に適切に対応する回答を記述してください。\\n\\n### 指示:\\n{instruction}\\n\\n### 回答:\\n\",\n",
        "    \"response_split\": \"### 回答:\"\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "hkL7dWrW4QmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "prompt_template = {\n",
        "    \"description\": \"Alpaca-LoRA カスタムテンプレート\",\n",
        "    \"prompt_input\": (\n",
        "        \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\"\n",
        "        \"以下に、タスクを説明する指示と、さらなる文脈を提供する入力がペアになっています。\\n\"\n",
        "        \"Write a response that appropriately completes the request.\\n要求に適切に対応する回答を記述してください。\\n\\n\"\n",
        "        \"### 指示:\\n{instruction}\\n\\n### 入力:\\n{input}\\n\\n### 回答:\\n\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"Below is an instruction that describes a task.\\n\"\n",
        "        \"以下に、タスクを説明する指示があります。\\n\\n\"\n",
        "        \"Write a response that appropriately completes the request.\\n要求に適切に対応する回答を記述してください。\\n\\n\"\n",
        "        \"### 指示:\\n{instruction}\\n\\n### 回答:\\n\"\n",
        "    ),\n",
        "    \"response_split\": \"### 回答:\",\n",
        "}\n",
        "\n",
        "with open('templates/custom.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(prompt_template, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "csV-ijJEDosI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning\n",
        "\n",
        "- https://github.com/tloen/alpaca-lora/blob/0e1a5d52a460d14aea2325e43c302972badb9cdd/finetune.py#L28\n",
        "- https://huggingface.co/blog/peft\n",
        "\n",
        "- 基本設定の時：\n",
        "    - 3h/1epoch in NVIDIA A100\n",
        "    - 12h/1epoch in NVIDIA T4\n",
        "\n",
        "- 注意事項\n",
        "    - 5epoch以上が精度が出やすい\n",
        "    - 学習率はデフォルトで3e-4. データセットによって要調整"
      ],
      "metadata": {
        "id": "DS9oi5trym6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py \\\n",
        "    --base_model 'decapoda-research/llama-7b-hf' \\\n",
        "    --data_path 'japanese_alpaca_data.json' \\\n",
        "    --output_dir './output' \\\n",
        "    --num_epochs 1 \\\n",
        "    --learning_rate 5e-4 \\\n",
        "    --val_set_size 2000 \\\n",
        "    --batch_size 512 \\\n",
        "    --micro_batch_size 16 \\\n",
        "    --prompt_template_name 'custom'"
      ],
      "metadata": {
        "id": "pMeHB20Jx7Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ckptをローカルに保存したい場合\n",
        "save_local: bool = False\n",
        "\n",
        "if save_local:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !mkdir /content/drive/MyDrive/LLaMa-Alpaca-LoRA\n",
        "    !cp -a output /content/drive/MyDrive/LLaMa-Alpaca-LoRA"
      ],
      "metadata": {
        "id": "5k4Vi0QSFJLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文章の生成\n",
        "\n",
        "- Gradioデモ：https://jalpaca.infertron.com/"
      ],
      "metadata": {
        "id": "04tyvP6AGaGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    \"decapoda-research/llama-7b-hf\",\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    \"kunishou/Japanese-Alpaca-LoRA-7b-v0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "15b7a7e67cf44dcb81f15c281df6920b",
            "651e32ee90ff4c688354dbc06561740f",
            "a84e08403c524ca2950241fed8f4bc56",
            "59e7caaca11c4878b59f422ba6110092",
            "be22fbf8545348af9553e7d922b64a88",
            "c1884f43f9a1401ea97a72e31bb0f22a",
            "2f960eec03d141a997cec16524383ce9",
            "4212706bd522490cbf9f8fbbe90db9a9",
            "61b073fe673f4b63ae4eff18453ae38b",
            "1cf05eda4d8b4f4fa962569ba1d32cc8",
            "dd37f54f56384eb88bc2703f2b1d70f5"
          ]
        },
        "id": "Mp_BDmysFw4r",
        "outputId": "22947d28-47a2-4d84-fab3-bd980c3880c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
            "The class this function is called from is 'LlamaTokenizer'.\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15b7a7e67cf44dcb81f15c281df6920b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"\"\"\n",
        "以下に、タスクを説明する指示と、さらなる文脈を提供する入力がペアになっています。\n",
        "### 指示:\n",
        "アルパカについて教えてください.\n",
        "### 回答:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "    PROMPT,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "input_ids = inputs[\"input_ids\"].cuda()\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=0.6,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=4.8,\n",
        ")\n",
        "\n",
        "print(\"Generating...\")\n",
        "generation_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    generation_config=generation_config,\n",
        "    return_dict_in_generate=True,\n",
        "    output_scores=True,\n",
        "    max_new_tokens=256,\n",
        ")\n",
        "\n",
        "for s in generation_output.sequences:\n",
        "    print(tokenizer.decode(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoMKbRPnKC3E",
        "outputId": "95cb9448-11e2-4980-870a-29dbf9bb7025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating...\n",
            " ⁇  \n",
            "以下に、タスクを説明する指示と、さらなる文脈を提供する入力がペアになっています。\n",
            "### 指示:\n",
            "アルパカについて教えてください.\n",
            "### 回答:\n",
            "Alpacas are native to South America, and they're known for their soft wool that can be spun into yarn or knitted with needles! They also have a very distinctive face shape - the ears point upward like an elf ear while being rounded on top (like Mickey Mouse). Alongside sheep & goats in farms around Peru/Bolivia where alpaaca herds live today; these animals were once used as pack mules by Incan people who lived there long ago before Europeans arrived...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIKX5fPSOLGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
