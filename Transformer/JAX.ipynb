{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input Embedding: https://enakai00.hatenablog.com/entry/2023/02/10/102036\n",
    "2. Multi-Head Attention: https://enakai00.hatenablog.com/entry/2023/02/10/144940\n",
    "3. https://enakai00.hatenablog.com/entry/2023/02/10/180105\n",
    "4. https://enakai00.hatenablog.com/entry/2023/02/10/195227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fit' from 'flax.training' (/Users/junhyeong.kim/Workspaces/JAX_transformer/.venv/lib/python3.11/site-packages/flax/training/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m random, numpy \u001b[39mas\u001b[39;00m jnp\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflax\u001b[39;00m \u001b[39mimport\u001b[39;00m linen \u001b[39mas\u001b[39;00m nn\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m fit, train_state, checkpoints\n\u001b[1;32m     11\u001b[0m plt\u001b[39m.\u001b[39mrcParams\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mfont.size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m12\u001b[39m})\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'fit' from 'flax.training' (/Users/junhyeong.kim/Workspaces/JAX_transformer/.venv/lib/python3.11/site-packages/flax/training/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from functools import partial\n",
    "\n",
    "import jax, optax\n",
    "from jax import random, numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import fit, train_state, checkpoints\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 3.97k/3.97k [00:00<00:00, 485kB/s]\n",
      "Downloading metadata: 100%|██████████| 3.28k/3.28k [00:00<00:00, 821kB/s]\n",
      "Downloading readme: 100%|██████████| 8.78k/8.78k [00:00<00:00, 1.45MB/s]\n",
      "WARNING:datasets.builder:No config specified, defaulting to: emotion/split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset emotion/split to /Users/junhyeong.kim/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 592k/592k [00:00<00:00, 8.51MB/s]\n",
      "Downloading data: 100%|██████████| 74.0k/74.0k [00:00<00:00, 5.07MB/s]\n",
      "Downloading data: 100%|██████████| 74.9k/74.9k [00:00<00:00, 4.98MB/s]\n",
      "Downloading data files: 100%|██████████| 3/3 [00:08<00:00,  2.81s/it]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 108.88it/s]\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset emotion downloaded and prepared to /Users/junhyeong.kim/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 547.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "emotions = load_dataset('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions['train']['text'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "model_ckpt = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "vocab_size = AutoConfig.from_pretrained(model_ckpt).vocab_size\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(text.split(' ')) for text in emotions['train']['text'] + emotions['validation']['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 128\n",
    "\n",
    "# training set\n",
    "train_set = tokenizer(\n",
    "    emotions['train']['text'],\n",
    "    max_length=text_length,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "train_text = np.array(train_set['input_ids'])\n",
    "train_mask = np.array(train_set['attention_mask'])\n",
    "train_label = np.eye(6)[emotions['train']['label']]\n",
    "\n",
    "# validation set\n",
    "valid_set = tokenizer(\n",
    "    emotions['validation']['text'],\n",
    "    max_length=text_length,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "valid_text = np.array(valid_set['input_ids'])\n",
    "valid_mask = np.array(valid_set['attention_mask'])\n",
    "valid_label = np.eye(6)[emotions['validation']['label']]\n",
    "\n",
    "# label map\n",
    "emotion_labels = emotions['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    embed_dim: int\n",
    "    text_length: int = text_length\n",
    "    vocab_size: int = vocab_size\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, input_ids, eval):\n",
    "        token_embeddings = nn.Embed(\n",
    "            self.vocab_size, self.embed_dim\n",
    "        )(input_ids)\n",
    "\n",
    "        position_ids = jnp.arange(self.text_length)\n",
    "        position_embeddings = nn.Embed(\n",
    "            self.text_length, self.embed_dim\n",
    "        )(position_ids)\n",
    "\n",
    "        # [N, トークン数, 埋め込み空間の次元] + [トークン数, 埋め込み空間の次元]\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "\n",
    "        embeddings = nn.LayerNorm(epsilon=1e-12)(embeddings)\n",
    "        embeddings = nn.Dropout(0.5, deterministic=eval)(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    Embed_0: {\n",
       "        embedding: (30522, 512),\n",
       "    },\n",
       "    Embed_1: {\n",
       "        embedding: (128, 512),\n",
       "    },\n",
       "    LayerNorm_0: {\n",
       "        bias: (512,),\n",
       "        scale: (512,),\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = Embeddings(embed_dim=512).init(random.PRNGKey(0), train_text[:1], eval=True)\n",
    "jax.tree_util.tree_map(lambda x: x.shape, variables['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 128), (3, 128, 512))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = train_text[:3]\n",
    "output = Embeddings(embed_dim=512).apply(variables, input_text, eval=True)\n",
    "\n",
    "input_text.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    head_dim: int\n",
    "    \n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):  # mask: [テキスト数, トークン数]\n",
    "        scores = jnp.matmul(q, jnp.transpose(k, (0, 2, 1)))\n",
    "        if mask is not None:\n",
    "            mask = jnp.tile(mask, mask.shape[-1]).reshape(\n",
    "                mask.shape[0], -1, mask.shape[-1]\n",
    "            )  # mask: [テキスト数, トークン数, トークン数]\n",
    "            scores = jnp.where(mask == 0, -jnp.inf, scores)\n",
    "        w = nn.softmax(scores / jnp.sqrt(self.head_dim))  # w: [テキスト数, トークン数（Query側）, トークン数（Key側）]\n",
    "        return jnp.matmul(w, v)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden_state, attention_mask): # hidden_state: [テキスト数, トークン数, 埋め込み空間の次元]\n",
    "        q = nn.Dense(features=self.head_dim)(hidden_state)  # q: [テキスト数, トークン数, Query の次元数]\n",
    "        k = nn.Dense(features=self.head_dim)(hidden_state)  # k: [テキスト数, トークン数, Key の次元数]\n",
    "        v = nn.Dense(features=self.head_dim)(hidden_state)  # v: [テキスト数, トークン数, Value の次元数]\n",
    "        output = self.scaled_dot_product_attention(\n",
    "            q=q,\n",
    "            k=k,\n",
    "            v=v,\n",
    "            mask=attention_mask\n",
    "        )\n",
    "        return output  # output: [テキスト数, トークン数, Value の次元数]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    num_heads: int\n",
    "    embed_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        head_dim = self.embed_dim // self.num_heads\n",
    "        self.attention_heads = [AttentionHead(head_dim=head_dim) for _ in jnp.arange(self.num_heads)]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden_state, attention_mask):\n",
    "        attention_outputs = [head(hidden_state, attention_mask) for head in self.attention_heads]\n",
    "        x = jnp.concatenate(attention_outputs, axis=-1)\n",
    "        x = nn.Dense(features=self.embed_dim)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    embed_dim: int\n",
    "    intermediate_size: int = 2_048\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, eval):\n",
    "        x = nn.Dense(features=self.intermediate_size)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.embed_dim)(x)\n",
    "        x = nn.Dropout(rate=0.1, deterministic=eval)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    num_heads: int\n",
    "    embed_dim: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            embed_dim=self.embed_dim\n",
    "        )\n",
    "        self.feed_forward = FeedForward(\n",
    "            embed_dim=self.embed_dim\n",
    "        )\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, attention_mask, eval):\n",
    "        x = x + self.attention(hidden_state=x, attention_mask=attention_mask)  # Skip connection\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = x + self.feed_forward(x, eval)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    num_heads: int\n",
    "    embed_dim: int\n",
    "    num_hidden_layers: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.embeddings = Embeddings(embed_dim=self.embed_dim)\n",
    "        self.layers = [\n",
    "            TransformerEncoderBlock(\n",
    "                num_heads=self.num_heads,\n",
    "                embed_dim=self.embed_dim\n",
    "            ) for _ in range(self.num_hidden_layers)\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, input_ids, attention_mask, eval):\n",
    "        x = self.embeddings(input_ids=input_ids, eval=eval)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x=x, attention_mask=attention_mask, eval=eval)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForSequenceClassifier(nn.Module):\n",
    "    num_labels: int\n",
    "    num_heads: int\n",
    "    embed_dim: int\n",
    "    num_hidden_layers: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.transformer_encoder = TransformerEncoder(\n",
    "            num_heads=self.num_heads,\n",
    "            embed_dim=self.embed_dim,\n",
    "            num_hidden_layers=self.num_hidden_layers\n",
    "        )\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, input_ids, attention_mask=None, eval=True):\n",
    "        x = self.transformer_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            eval=eval\n",
    "            )[:, 0, :]  # select [CLS] token\n",
    "        x = nn.Dropout(rate=0.1, deterministic=eval)(x)\n",
    "        logits = nn.Dense(features=self.num_labels)(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
