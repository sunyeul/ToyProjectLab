{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunyeul/ToyProjectLab/blob/feature%2Fnanogpt_tutorial/nanoGPT/bigram_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OQA6_SNxlY-",
        "outputId": "267f8084-6b3c-47d6-d7d3-9bb3dc1225f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-23 16:41:13--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-04-23 16:41:13 (160 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# データセットをダウンロードしましょう。\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from dataclasses import dataclass\n",
        "\n",
        "torch.manual_seed(3655)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    vocab_size: int = 65\n",
        "    batch_size: int = 8\n",
        "    block_size: int = 16 # what is the maximum context length for predictions?\n",
        "\n",
        "    train_size: float = 0.8  # valid_sizeは自動で0.2に決まる\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "PnZg4pgG0jR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SAFFbOYxlZC",
        "outputId": "d9a92869-b815-4214-fb6f-9de76a085942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(len(text))\n",
        "print(text[:1_000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkJ-bUzPxlZE",
        "outputId": "bc4a2337-810d-416c-f243-d5d5cae70e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "# テキストから重複を除いた文字列を取得し、アルファベット順にソートする\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"\".join(chars))\n",
        "\n",
        "# ボキャブラリーのサイズを取得する\n",
        "vocab_size = len(chars)\n",
        "Config.vocab_size = vocab_size\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文字列をインデックスに変換するための辞書を作成する\n",
        "# s2iは文字列をインデックスに変換するための辞書\n",
        "s2i = {ch:i for i, ch in enumerate(chars)}\n",
        "\n",
        "# インデックスを文字列に変換するための辞書を作成する\n",
        "# i2sはインデックスを文字列に変換するための辞書\n",
        "i2s = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# 文字列を数値のリストに変換する関数を定義する\n",
        "encode = lambda s: [s2i[c] for c in s]\n",
        "\n",
        "# 数値のリストを文字列に変換する関数を定義する\n",
        "decode = lambda l: ''.join([i2s[i] for i in l])"
      ],
      "metadata": {
        "id": "tVRHSYZK0f6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストを数値のリストに変換する\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# データの形状とデータ型を表示する\n",
        "print(data.shape, data.dtype)\n",
        "\n",
        "# 先頭の1000文字を表示する\n",
        "print(data[:1000]) # GPTにとっては、ここで表示される1000文字は以下のようになる"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbvQrxBb0s5g",
        "outputId": "96c06271-788b-47cf-bf13-696d57de8f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPakLTBJxlZF"
      },
      "outputs": [],
      "source": [
        "# 学習用データと検証用データに分割する\n",
        "n = int(Config.train_size * len(data))\n",
        "\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用データを最初のConfig.block_size文字だけに限定する\n",
        "x = train_data[:Config.block_size]\n",
        "\n",
        "# 学習用データを2文字目から最初のConfig.block_size+1文字に限定する\n",
        "y = train_data[1:Config.block_size+1]\n",
        "\n",
        "# Config.block_size回繰り返す\n",
        "for t in range(Config.block_size):\n",
        "\n",
        "    # 入力となる文字列を1文字からt+1文字までに限定する\n",
        "    context = x[:t+1]\n",
        "\n",
        "    # 正解の文字を取得する\n",
        "    target = y[t]\n",
        "\n",
        "    # 入力がcontextのときに、正解がtargetであることを表示する\n",
        "    print(f\"入力が{context}のときに、正解は{target}です\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_WgbEdw15o1",
        "outputId": "2cf70998-29f2-40fd-8ad2-11172bf459e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力がtensor([18])のときに、正解は47です\n",
            "入力がtensor([18, 47])のときに、正解は56です\n",
            "入力がtensor([18, 47, 56])のときに、正解は57です\n",
            "入力がtensor([18, 47, 56, 57])のときに、正解は58です\n",
            "入力がtensor([18, 47, 56, 57, 58])のときに、正解は1です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1])のときに、正解は15です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15])のときに、正解は47です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47])のときに、正解は58です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58])のときに、正解は47です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])のときに、正解は64です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64])のときに、正解は43です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43])のときに、正解は52です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52])のときに、正解は10です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10])のときに、正解は0です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0])のときに、正解は14です\n",
            "入力がtensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14])のときに、正解は43です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    # 入力と正解の小さなバッチを生成する\n",
        "    # splitが'train'の場合は学習用データから、'val'の場合は検証用データからデータを取得する\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    \n",
        "    # バッチを開始するためのランダムなインデックスを生成する\n",
        "    idx = torch.randint(high=len(data) - Config.block_size, size=(Config.batch_size,))\n",
        "    \n",
        "    # xは、block_sizeの長さのシーケンスのバッチである\n",
        "    x = torch.stack([data[i:i+Config.block_size] for i in idx])  # [batch_size, block_size]\n",
        "    \n",
        "    # yは、xと同じものであるが、1つずつずれている\n",
        "    y = torch.stack([data[i+1:i+Config.block_size+1] for i in idx])  # [batch_size, block_size]\n",
        "    \n",
        "    return x.to(Config.device), y.to(Config.device)"
      ],
      "metadata": {
        "id": "6Bcrwukc15mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3QdM1D315hN",
        "outputId": "1e707c6a-ae42-492a-8b32-e29e48f98568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([8, 16])\n",
            "tensor([[59, 43, 43, 52, 12,  0,  0, 29, 33, 17, 17, 26,  1, 25, 13, 30],\n",
            "        [ 1, 63, 53, 59, 56,  1, 55, 59, 43, 43, 52,  6,  0, 13, 52, 42],\n",
            "        [ 0, 18, 39, 56, 43, 61, 43, 50, 50,  2,  1, 19, 53, 42,  1, 49],\n",
            "        [57, 43, 42,  1, 61, 47, 58, 46,  1, 58, 46, 43,  1, 40, 50, 53],\n",
            "        [40, 39, 41, 49, 10,  0, 32, 46, 43, 56, 43,  1, 47, 57,  1, 39],\n",
            "        [ 1, 49, 47, 52, 45, 11,  1, 39, 52, 42,  1, 52, 53, 58,  1, 58],\n",
            "        [ 1, 58, 46, 53, 59,  1, 46, 39, 57, 58,  1, 52, 53,  1, 41, 39],\n",
            "        [56, 53, 59, 45, 46, 58,  1, 44, 53, 56, 58, 46,  1, 50, 43, 57]],\n",
            "       device='cuda:0')\n",
            "targets:\n",
            "torch.Size([8, 16])\n",
            "tensor([[43, 43, 52, 12,  0,  0, 29, 33, 17, 17, 26,  1, 25, 13, 30, 19],\n",
            "        [63, 53, 59, 56,  1, 55, 59, 43, 43, 52,  6,  0, 13, 52, 42,  1],\n",
            "        [18, 39, 56, 43, 61, 43, 50, 50,  2,  1, 19, 53, 42,  1, 49, 52],\n",
            "        [43, 42,  1, 61, 47, 58, 46,  1, 58, 46, 43,  1, 40, 50, 53, 53],\n",
            "        [39, 41, 49, 10,  0, 32, 46, 43, 56, 43,  1, 47, 57,  1, 39,  1],\n",
            "        [49, 47, 52, 45, 11,  1, 39, 52, 42,  1, 52, 53, 58,  1, 58, 46],\n",
            "        [58, 46, 53, 59,  1, 46, 39, 57, 58,  1, 52, 53,  1, 41, 39, 59],\n",
            "        [53, 59, 45, 46, 58,  1, 44, 53, 56, 58, 46,  1, 50, 43, 57, 57]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(Config.batch_size): # batch dimension\n",
        "    for t in range(Config.block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0YlFCLE15eb",
        "outputId": "8268ac44-af2a-454c-8538-9154ce835631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [59] the target: 43\n",
            "when input is [59, 43] the target: 43\n",
            "when input is [59, 43, 43] the target: 52\n",
            "when input is [59, 43, 43, 52] the target: 12\n",
            "when input is [59, 43, 43, 52, 12] the target: 0\n",
            "when input is [59, 43, 43, 52, 12, 0] the target: 0\n",
            "when input is [59, 43, 43, 52, 12, 0, 0] the target: 29\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29] the target: 33\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33] the target: 17\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17] the target: 17\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17, 17] the target: 26\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17, 17, 26] the target: 1\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17, 17, 26, 1] the target: 25\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17, 17, 26, 1, 25] the target: 13\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17, 17, 26, 1, 25, 13] the target: 30\n",
            "when input is [59, 43, 43, 52, 12, 0, 0, 29, 33, 17, 17, 26, 1, 25, 13, 30] the target: 19\n",
            "when input is [1] the target: 63\n",
            "when input is [1, 63] the target: 53\n",
            "when input is [1, 63, 53] the target: 59\n",
            "when input is [1, 63, 53, 59] the target: 56\n",
            "when input is [1, 63, 53, 59, 56] the target: 1\n",
            "when input is [1, 63, 53, 59, 56, 1] the target: 55\n",
            "when input is [1, 63, 53, 59, 56, 1, 55] the target: 59\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59] the target: 43\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43] the target: 43\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43] the target: 52\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52] the target: 6\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52, 6] the target: 0\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52, 6, 0] the target: 13\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52, 6, 0, 13] the target: 52\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52, 6, 0, 13, 52] the target: 42\n",
            "when input is [1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52, 6, 0, 13, 52, 42] the target: 1\n",
            "when input is [0] the target: 18\n",
            "when input is [0, 18] the target: 39\n",
            "when input is [0, 18, 39] the target: 56\n",
            "when input is [0, 18, 39, 56] the target: 43\n",
            "when input is [0, 18, 39, 56, 43] the target: 61\n",
            "when input is [0, 18, 39, 56, 43, 61] the target: 43\n",
            "when input is [0, 18, 39, 56, 43, 61, 43] the target: 50\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50] the target: 50\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50] the target: 2\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2] the target: 1\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2, 1] the target: 19\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2, 1, 19] the target: 53\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2, 1, 19, 53] the target: 42\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2, 1, 19, 53, 42] the target: 1\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2, 1, 19, 53, 42, 1] the target: 49\n",
            "when input is [0, 18, 39, 56, 43, 61, 43, 50, 50, 2, 1, 19, 53, 42, 1, 49] the target: 52\n",
            "when input is [57] the target: 43\n",
            "when input is [57, 43] the target: 42\n",
            "when input is [57, 43, 42] the target: 1\n",
            "when input is [57, 43, 42, 1] the target: 61\n",
            "when input is [57, 43, 42, 1, 61] the target: 47\n",
            "when input is [57, 43, 42, 1, 61, 47] the target: 58\n",
            "when input is [57, 43, 42, 1, 61, 47, 58] the target: 46\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46] the target: 1\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1] the target: 58\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58] the target: 46\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58, 46] the target: 43\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58, 46, 43] the target: 1\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58, 46, 43, 1] the target: 40\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58, 46, 43, 1, 40] the target: 50\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58, 46, 43, 1, 40, 50] the target: 53\n",
            "when input is [57, 43, 42, 1, 61, 47, 58, 46, 1, 58, 46, 43, 1, 40, 50, 53] the target: 53\n",
            "when input is [40] the target: 39\n",
            "when input is [40, 39] the target: 41\n",
            "when input is [40, 39, 41] the target: 49\n",
            "when input is [40, 39, 41, 49] the target: 10\n",
            "when input is [40, 39, 41, 49, 10] the target: 0\n",
            "when input is [40, 39, 41, 49, 10, 0] the target: 32\n",
            "when input is [40, 39, 41, 49, 10, 0, 32] the target: 46\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46] the target: 43\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43] the target: 56\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56] the target: 43\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56, 43] the target: 1\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56, 43, 1] the target: 47\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56, 43, 1, 47] the target: 57\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56, 43, 1, 47, 57] the target: 1\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56, 43, 1, 47, 57, 1] the target: 39\n",
            "when input is [40, 39, 41, 49, 10, 0, 32, 46, 43, 56, 43, 1, 47, 57, 1, 39] the target: 1\n",
            "when input is [1] the target: 49\n",
            "when input is [1, 49] the target: 47\n",
            "when input is [1, 49, 47] the target: 52\n",
            "when input is [1, 49, 47, 52] the target: 45\n",
            "when input is [1, 49, 47, 52, 45] the target: 11\n",
            "when input is [1, 49, 47, 52, 45, 11] the target: 1\n",
            "when input is [1, 49, 47, 52, 45, 11, 1] the target: 39\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39] the target: 52\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52] the target: 42\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42] the target: 1\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42, 1] the target: 52\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42, 1, 52] the target: 53\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42, 1, 52, 53] the target: 58\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42, 1, 52, 53, 58] the target: 1\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42, 1, 52, 53, 58, 1] the target: 58\n",
            "when input is [1, 49, 47, 52, 45, 11, 1, 39, 52, 42, 1, 52, 53, 58, 1, 58] the target: 46\n",
            "when input is [1] the target: 58\n",
            "when input is [1, 58] the target: 46\n",
            "when input is [1, 58, 46] the target: 53\n",
            "when input is [1, 58, 46, 53] the target: 59\n",
            "when input is [1, 58, 46, 53, 59] the target: 1\n",
            "when input is [1, 58, 46, 53, 59, 1] the target: 46\n",
            "when input is [1, 58, 46, 53, 59, 1, 46] the target: 39\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39] the target: 57\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57] the target: 58\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58] the target: 1\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1] the target: 52\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1, 52] the target: 53\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1, 52, 53] the target: 1\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1, 52, 53, 1] the target: 41\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1, 52, 53, 1, 41] the target: 39\n",
            "when input is [1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1, 52, 53, 1, 41, 39] the target: 59\n",
            "when input is [56] the target: 53\n",
            "when input is [56, 53] the target: 59\n",
            "when input is [56, 53, 59] the target: 45\n",
            "when input is [56, 53, 59, 45] the target: 46\n",
            "when input is [56, 53, 59, 45, 46] the target: 58\n",
            "when input is [56, 53, 59, 45, 46, 58] the target: 1\n",
            "when input is [56, 53, 59, 45, 46, 58, 1] the target: 44\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44] the target: 53\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53] the target: 56\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56] the target: 58\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56, 58] the target: 46\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56, 58, 46] the target: 1\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56, 58, 46, 1] the target: 50\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56, 58, 46, 1, 50] the target: 43\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56, 58, 46, 1, 50, 43] the target: 57\n",
            "when input is [56, 53, 59, 45, 46, 58, 1, 44, 53, 56, 58, 46, 1, 50, 43, 57] the target: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        \n",
        "        # トークンの埋め込み表を作成する\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.vocab_size, device=Config.device)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        \"\"\"\n",
        "        バイグラム言語モデルの順伝播関数\n",
        "        \"\"\"\n",
        "        # logitsは、モデルのログオッズを含む形状が[B、T、C]のテンソルです\n",
        "        logits = self.token_embedding_table(idx)  # [B, T, C]\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # [B, T, C]\n",
        "            B, T, C = logits.shape\n",
        "            # [B*T, C]\n",
        "            logits = logits.view(B*T, C)\n",
        "            # [B*T]\n",
        "            targets = targets.view(B*T)\n",
        "            # lossは、クロスエントロピー損失を示す\n",
        "            loss = F.cross_entropy(logits, targets)  # loss is the cross entropy loss\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        \"\"\"\n",
        "        バイグラム言語モデルの生成関数\n",
        "        \"\"\"\n",
        "        # idxは、現在の文脈のインデックスの(B, T)配列である\n",
        "        for _ in range(max_new_tokens):\n",
        "            # 予測を取得する\n",
        "            logits, _ = self(idx)  # targets is None\n",
        "            # 最後の時間ステップにフォーカスする\n",
        "            logits = logits[:, -1, :]  # [B, C]\n",
        "            # 確率を取得するためにsoftmaxを適用する\n",
        "            probs = F.softmax(logits, dim=-1)  # [B, C]\n",
        "            # 分布からサンプリングする\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # [B, 1]\n",
        "            # サンプリングされたインデックスを実行中のシーケンスに追加する\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # [B, T+1]\n",
        "        return idx"
      ],
      "metadata": {
        "id": "Dd5kQSGi1Wzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-I32pOoxlZG",
        "outputId": "00208844-98c1-45b4-d9ee-d55a08cd0c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 65])\n",
            "tensor(4.6667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "WBiuOhZGs:;:ZxBi-.DoBii3&ssFRP;UpMFqkxoQVj'Szodw,$SqcG zVzUnNrR-quLnDiAYs3dxaC zj.nuSEj;KgxjGmm.,dCf\n"
          ]
        }
      ],
      "source": [
        "# モデルをインスタンス化する\n",
        "model = BigramLanguageModel(config=Config)\n",
        "\n",
        "# 順伝播を実行し、ログオッズと損失を取得する\n",
        "logits, loss = model(xb, yb)\n",
        "\n",
        "# logitsの形状と損失を表示する\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# モデルによって生成されたテキストを表示する\n",
        "generated_text = model.generate(idx=torch.zeros((1, 1,), dtype=torch.long, device=Config.device), max_new_tokens=100)[0].tolist()\n",
        "decoded_text = decode(generated_text)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "81873ab844fb45bbb52020ac9f6b4c02",
            "e4d23eca5d6d47ed9be7a13b49aaeda9",
            "27c7fde78ef94f01ae99a2a969dd6451",
            "65420a7a21d646fc824cc8da2c1818ba",
            "5e58774f22544973b14822a9275c3b10",
            "7ceeed1060d7419990b75c35c0c51ee2",
            "7973dc81c8724955b8e9a7cbc3084098",
            "94c968cc549445e99c30840ce47e24ba",
            "71be41a4be6f4711927bad37ab8aa3f3",
            "fe9fff0e61e94fc6ba5b761c0025b6b9",
            "3dba5665642b4a8db84615d1ca354a9b"
          ]
        },
        "id": "Ae3ZhHTvxlZH",
        "outputId": "2e0e3812-0256-4fb4-c1b6-71407f585f89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81873ab844fb45bbb52020ac9f6b4c02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.518681287765503\n"
          ]
        }
      ],
      "source": [
        "# PyTorchのオプティマイザを作成する\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "# 100,000回のステップを実行する\n",
        "for steps in tqdm(range(100_000)):\n",
        "    \n",
        "    # データのバッチをサンプリングする\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # 損失を評価する\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # 勾配をゼロに設定して、逆伝播を計算する\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "\n",
        "    # パラメータを更新する\n",
        "    optimizer.step()\n",
        "\n",
        "# 損失を表示する\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxcdYXSFxlZH",
        "outputId": "096e34cc-806b-4a4f-ce63-48710f4d9512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F d my cu HEY:\n",
            "aser s Thio ke'toule touk or!\n",
            "UFoueal clou bradobl s tht\n",
            "Bow\n",
            "Wimennk, otono meeang,\n",
            "Fang g ponkison?\n",
            "hcons thy ird tee fu d w LA:\n",
            "Ye ADUTar ho th atthed oreeonsw, lly ellllyom'lkepl! as t\n",
            "Ty oor:\n",
            "I hindeng hathe quris semus,\n",
            "Fintharngririmead? brd llsceerom, s\n",
            "Whe s nd!\n",
            "\n",
            "The h wave t:\n",
            "\n",
            "Alithede\n",
            "OOLA:\n",
            "BE: thithisestuchengen th,\n",
            "D ier?\n",
            "AR:\n",
            "OUCOLIfaishou k p; their Oh 'thsowsan,\n",
            "\n",
            "Whe,\n",
            "N byork fom t youpizas?\n",
            "\n",
            "Ane e,\n",
            "HANurd\n",
            "\n",
            "LLED s t wicurtea t br-e he thelll th upostory hak min Tweal\n"
          ]
        }
      ],
      "source": [
        "# モデルによって生成されたテキストを表示する\n",
        "generated_text = model.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=Config.device), max_new_tokens=500)[0].tolist()\n",
        "decoded_text = decode(generated_text)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwi8v6MQxlZI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81873ab844fb45bbb52020ac9f6b4c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d23eca5d6d47ed9be7a13b49aaeda9",
              "IPY_MODEL_27c7fde78ef94f01ae99a2a969dd6451",
              "IPY_MODEL_65420a7a21d646fc824cc8da2c1818ba"
            ],
            "layout": "IPY_MODEL_5e58774f22544973b14822a9275c3b10"
          }
        },
        "e4d23eca5d6d47ed9be7a13b49aaeda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ceeed1060d7419990b75c35c0c51ee2",
            "placeholder": "​",
            "style": "IPY_MODEL_7973dc81c8724955b8e9a7cbc3084098",
            "value": "100%"
          }
        },
        "27c7fde78ef94f01ae99a2a969dd6451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c968cc549445e99c30840ce47e24ba",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71be41a4be6f4711927bad37ab8aa3f3",
            "value": 100000
          }
        },
        "65420a7a21d646fc824cc8da2c1818ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9fff0e61e94fc6ba5b761c0025b6b9",
            "placeholder": "​",
            "style": "IPY_MODEL_3dba5665642b4a8db84615d1ca354a9b",
            "value": " 100000/100000 [01:39&lt;00:00, 1044.74it/s]"
          }
        },
        "5e58774f22544973b14822a9275c3b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ceeed1060d7419990b75c35c0c51ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7973dc81c8724955b8e9a7cbc3084098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94c968cc549445e99c30840ce47e24ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71be41a4be6f4711927bad37ab8aa3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9fff0e61e94fc6ba5b761c0025b6b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dba5665642b4a8db84615d1ca354a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}